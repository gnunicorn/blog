NSA is an example case of big data. And though what they take out of the data and the size of the impact it has for every one of us and democracy as a whole is truly threatening, it also shows what is possible with data today, that we can crawl huge amounts of data, looking and finding hidden treasures. From history we know that it will not take long until every one will have access to computing power the NSA has today. And we will also have all this data, we started recording now or pretty recently. Which raises the question: how shall we ensure fair- and openness of any data set we are collecting for big data purposes? And how does this work with privacy?

To look into that further let's move away from the NSA example to a less life threatening topic and look into the quantify self movement: their goal is more modest but still in the classic range of big data: they are up to create a data set of human life information, bigger than any research study could ever collect. And though this is an amazing idea, it raises that same question: how to ensure the openness and accessibility to this data? Companies by definition have an agenda and so what if the data shows is against the agenda of the company collecting and structuring that information? The recent behavior of Facebook, Twitter and also Google have show that those companies can't be trusted but this data needs to be public and accessible. But how? How could one publish this kinda of so extremely personal information and still respecting the privacy of people? Opt-in only? Anonymisation? 

The problem with requiring the user to explicitly say they want to share their information -- like Firefox, LibreOffice or many Linux Distributions do it -- is that you'll always reach just a certain demographic of the people: exactly those, who already believes in that type of thing. This isn't only bad because it limits the amount of data you have in numbers, it is also not a real representation, making every conclusion one can draw from it only within certain boundaries, too. And as such making this data useless for real research studies.  

So then collecting all data but anonymising it sounds like the only way then. But we have also a major problem with anonymising -- two actually. On one side a lot of data only makes sense if know a certain context around it, too. At least that certain data points are collected from the same entity. As a simple example: if you were able to totally anonymise every web request made to a webpage and decouple them, it would be impossible to look for as simple information as how users navigate the website, rendering the Data useless for any deeper looks. We have to admit that many big data techniques base on profiling, collecting and grouping.

The other problem lies in the question whether it even technically possible to anonymise the information? The [recent case of an algorithm which made it possible to identify people within TOR] -- a proxy network which's sole purpose is to anonymise web-traffic -- raised that question again. Considering that the data is only collected now but stored for a long time and accessible to the public for decades to come, we can safely assume that any method we've been using today to anonymise privacy data will be broken at some point and compromised through future progress in technology.

It will always be impossible to have a big collection of data accessible to all and without any privacy concerns. It sounds like a classic "you can only pick two out of three"-situation. But which ones those are isn't up to us at the moment, as many companies decide this for us by just keeping the information for themselves (non anonymised of course) and we don't have any access whatsoever. And while I do believe it should be possible for companies to make use of this kind of data, we have to rethink as society what the rules have to be about this. It is simply too much power in their hands right now and to come. This is a discussion that needs to happen now and one of the many discussing the NSA case triggered. 
